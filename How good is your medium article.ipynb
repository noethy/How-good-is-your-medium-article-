{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "[\"How good is your medium article?\"](https://www.kaggle.com/c/how-good-is-your-medium-article/overview/description) competition on Kaggle. Training set is comprised of articles published before Jul.1, 2017 and testing set consists articles published from Jul.1, 2017 till Mar. 3, 2018. Data is given in JSON format. The goal is to predict number of \"claps\" in the test set. This target is log1p transformed, log1p(x) = log(1+x). The evaluation metric for this competition is Mean Absolute Error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Take a first look at our training data in terminal\n",
    "cd /Users/Cheryl/Dropbox/Courses/Open\\ ml\\ ai/mlcourse.ai-master/data/kaggle_medium\n",
    "\n",
    "head train.json > 1.json\n",
    "\n",
    "pip install pyLDAvis\n",
    "\n",
    "pip install gensim\n",
    "\n",
    "I am going to explore only the \"content\" of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Cheryl/anaconda3/lib/python3.7/site-packages/socks.py:58: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Callable\n",
      "/Users/Cheryl/anaconda3/lib/python3.7/site-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "/Users/Cheryl/anaconda3/lib/python3.7/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.linear_model import Ridge\n",
    "import pyLDAvis.gensim\n",
    "import gensim\n",
    "from gensim.matutils  import Sparse2Corpus\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Clean and load data\n",
    "Clean HTML tags from an article content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read a JavaScript Object Notation (JSON) line without crashing on escape characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_line(line=None):\n",
    "    result = None\n",
    "    try:        \n",
    "        result = json.loads(line)\n",
    "    except Exception as e:      \n",
    "        idx_to_replace = int(str(e).split(' ')[-1].replace(')',''))      \n",
    "        new_line = list(line)\n",
    "        new_line[idx_to_replace] = ' '\n",
    "        new_line = ''.join(new_line)     \n",
    "        return read_json_line(line=new_line)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '/Users/Cheryl/Dropbox/Courses/Open ml ai/mlcourse.ai-master/data/kaggle_medium'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Preparing content data for NLP models. \n",
    "- Bag of Words approach by extracting features through CountVectorizer.\n",
    "- Topic modeling with Latent Dirichlet Allocation (LDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(path_to_inp_json):\n",
    "    output_list = []\n",
    "    with open(path_to_inp_json, encoding='utf-8') as inp_file:\n",
    "        for line in tqdm_notebook(inp_file):\n",
    "            json_data = read_json_line(line)\n",
    "            content = json_data['content'].replace('\\n', ' ').replace('\\r', ' ')\n",
    "            content_no_html_tags = strip_tags(content)\n",
    "            output_list.append(content_no_html_tags)\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f69318a1a634b32a8cea328db887a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 5min 56s, sys: 8.43 s, total: 6min 4s\n",
      "Wall time: 6min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_content = prep(path_to_inp_json=os.path.join(PATH_TO_DATA, 'train.json'),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8efc469157453b9cf7b0cc3b23c491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 3min 23s, sys: 5.12 s, total: 3min 28s\n",
      "Wall time: 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_content = prep(path_to_inp_json=os.path.join(PATH_TO_DATA, 'test.json'),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to take a look at the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Oscar BoysonNew York City FilmmakingDec 13, 2016The Future of\\xa0CitiesOrganic Filmmaking and City Re-ImaginingWhat does “the future of cities” mean? To much of the developing world, it might be as simple as aspiring to having your own toilet, rather than sharing one with over 100 people. To a family in Detroit, it could mean having non-toxic drinking water. For planners and mayors, it’s about a lot of things\\u200a—\\u200asustainability, economy, inclusivity, and resilience. Most of us can hope we can spend a little less time on our commutes to work and a little more time with our families. For a rich white dude up in a 50th floor penthouse, “the future of cities” might mean zipping around in a flying car while a robot jerks you off and a drone delivers your pizza. For many companies, the future of cities is simply about business and money, presented to us as buzzwords like “smart city” and “the city of tomorrow.”I started shooting the “The Future of a Cities” as a collaboration with the The Nantucket Project, but it really took shape when hundreds of people around the world responded to a scrappy video I made asking for help.Folks of all ages, from over 75 countries, volunteered their time, thoughts, work, and footage so that I could expand the scope of the piece and connect with more people in more cities. This strategy saved me time and money, but it also clarified the video’s purpose, which inspired me to put more energy into the project in order to get it right. I was reading Jan Gehl, Jane Jacobs, Edward Glaeser, etc. and getting excited about their ideas\\u200a—\\u200aafter seeing what mattered to the people I met in person and watching contributions from those I didn’t, the video gained focus and perspective.If I hired a production services outfit to help me film Mumbai, it would actually be a point of professional pride for the employees to deliver the Mumbai they think I want to see. If some young filmmakers offer to show me around their city and shoot with me for a day, we’re operating on another level, and a very different portrait of a city emerges. In the first scenario, my local collaborators get paid and I do my best to squeeze as much work out of the time period paid for as possible. In the second, the crew accepts more responsibility but gains ownership, hopefully leaving the experience feeling more empowered.Architect and former mayor of Curitiba Jaime Lerner famously said “if you want creativity, take a zero off your budget. If you want sustainability, take off two zeros.” It’s been my experience that this sustainability often goes hand-in-hand with humanity, and part of what I love about working with less resources and money is that it forces you to treat people like human beings. Asking someone to work with less support or equipment, or to contribute more time for less money, requires a mutual understanding between two people. If each person can empathize for the other, it’s been my experience that we’ll feel it in the work\\u200a—\\u200aboth in the process and on screen.Organic filmmaking requires you to keep your crew small and your footprint light. You start filming with one idea in mind, but the idea changes each day as elements you could never have anticipated inform the bigger picture. You make adjustments and pursue new storylines. You edit a few scenes, see what’s working and what’s not, then write new scenes. Shoot those, cut them in, then go back and write more. Each part of the process talks to the other. The movie teaches itself to be a better movie. Because organic is complicated, it can be tricky to defend and difficult to scale up, but because it’s cheap and low-resource, it’s easier to experiment. Learning about the self-organizing, living cities that I did on this project informed how we made the video. And looking at poorly planned urban projects reminded me of the broken yet prevailing model for making independent film in the U.S., where so many films are bound to fail\\u200a—\\u200aoften in a way a filmmaker doesn’t recover from\\u200a—\\u200abefore they even begin.Jane Jacobs said that “cities have the capability of providing something for everybody, only because, and only when, they are created by everybody.” I’ve worked on videos for companies, for the guy in the penthouse, for nobody in particular, in the developing world, with rich people and poor people, for me, for my friends, and for artists. I’m so thankful for everybody who allowed me to make this film the way we did, and I hope the parallels between filmmaking and city building\\u200a—\\u200awhere the stakes are so much higher\\u200a—\\u200aaren’t lost on anyone trying to make their city a better place. We should all be involved. The most sustainable future is a future that includes us all.“The Future of Cities” Reading\\xa0List(There’s a longer list I discovered recently from Planetizen HERE but these are the ones I got into on this project\\u200a—\\u200aI’m excited to read many more)The Death and Life of American Cities by Jane JacobsThe Triumph of the City: How Our Greatest Invention Makes Us Richer, Smarter, Greener, Healthier, and Happier by Edward GlaeserCities for People and Life Between Buildings by Jan GehlThe Well-Tempered City: What Modern Science, Ancient Civilizations, and Human Nature Teach Us About the Future of Urban Life by Jonathan Rose(just came out\\u200a—\\u200aincredible)Walkable City: How Downtown Can Save America, One Step at a Time by Jeff SpeckThe City of Tomorrow: Sensors, Networks, Hackers, and the Future of Urban Life by Carlo Ratti and Matthew ClaudelHappy City: Transforming Our Lives Through Urban Design by Charles MontgomeryDream Cities: Seven Urban Ideas That Shape the World by Wade GrahamConnectography: Mapping The Future of Global Civilization by Parag KhannaDelirious New York by Rem KoolhaasLow Life and The Other Paris by Luc SanteA History of Future Cities by Daniel BrookStreetfight: Handbook for the Urban Revolution by Janette Sadik-Khan and Seth SolomonowTactical Urbanism: Short-term Action for Long-Term Change by Mike Lydon & Anthony GarciaLiving In The Endless City, edited by Ricky Burdett and Deyan Sudjic“The Future of Cities” Select Interviewees:David Hertz & Sky SourceVicky Chan & Avoid Obvious ArchitectsCarlo Ratti: Director, MIT Senseable City Lab Founding Partner, Carlo Ratti AssociatiEdward Glaeser: Fred and Eleanor Glimp Professor of Economics, Harvard University Author of The Triumph of the CityHelle Søholt: Founding Parner & CEO, Gehl ArchitectsRicky Burdett: Director, LSE Cities/Urban AgeLauren Lockwood, Chief Digital Officer, City of BostonPablo Viejo: Smart Cities Expert & CTO V&V Innovations, SingaporeMatias Echanove & Urbz, MumbaiJanette Sadik-Khan: Author, Advisor, & Former NYC DOT CommissionerAbess Makki: CEO, City InsightDr. Parag Khanna: Author of ConnectographyStan Gale: CEO of Gale International, Developer of Songdo IBDDr. Jockin Arputham: President, Slum Dwellers InternationalMorton Kabell: Mayor for Technical & Environmental Affairs, CopenhagenThanks to Ryan Bradley and Noah Rabinowitz. Smart CitiesUrban PlanningFutureUrbanizationFilmmakingOne clap, two clap, three clap, forty?By clapping more or less, you can signal to us which stories really stand out.Oscar BoysonNew York City Filmmaking']\n"
     ]
    }
   ],
   "source": [
    "print(train_content[19:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bag-of-Words approach \n",
    "\n",
    "and Ridge model (?) explain why use ridge model first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot tokens? correlation between word freq and # of claps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BoW = CountVectorizer(max_features=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 13s, sys: 7.87 s, total: 2min 21s\n",
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = BoW.fit_transform(train_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 4.09 s, total: 1min 15s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test = BoW.fit_transform(test_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62313, 100000), (34645, 100000))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_log1p_recommends.csv'), \n",
    "                           index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62313, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_target['log_recommends'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate classifier using holdout method (70% for training and 30% for validating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_partition = int(0.7 * train_target.shape[0])\n",
    "X_train_part = X_train[:train_partition, :]\n",
    "y_train_part = y_train[:train_partition]\n",
    "X_valid =  X_train[train_partition:, :]\n",
    "y_valid = y_train[train_partition:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 37s, sys: 2.18 s, total: 3min 40s\n",
      "Wall time: 3min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=2, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ridge.fit(X_train_part, y_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_valid = ridge.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Classifier validation on training data')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_valid, bins=20, alpha=.5, color='red', label='original', range=(0,10))\n",
    "plt.hist(ridge_valid, bins=20, alpha=.5, color='blue', label='prediction', range=(0,10))\n",
    "plt.legend()\n",
    "plt.title('Classifier validation on training data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caculate MAE for training data set, recall that our target (number of claps) is log1p transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.30587271708131, 2.6909088077130057)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_valid = mean_absolute_error(y_valid, ridge_valid)\n",
    "mae_valid, np.expm1(mae_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction for validation is not perfect, but somewhat acceptable. On average, this model yields approximately 2.7 errors in predicting the number of claps. Let's see how it works for predicting the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 2s, sys: 4.15 s, total: 5min 6s\n",
      "Wall time: 5min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=2, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 256 ms, sys: 816 ms, total: 1.07 s\n",
      "Wall time: 1.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ridge_pred = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission_file(prediction, filename,\n",
    "    path_to_sample=os.path.join(PATH_TO_DATA, 'sample_submission.csv')):\n",
    "    submission = pd.read_csv(path_to_sample, index_col='id')\n",
    "    submission['log_recommends'] = prediction\n",
    "    submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(prediction=ridge_pred, filename='BoW_ridge.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle gives this submission with MAE approximately 2.12, so this model yields about 2.12 errors in prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Topic modeling with LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack sparse matrix from test and train. Transform to gensim corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "full_sparse_data =  sparse.vstack([X_train, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_corpus_data = gensim.matutils.Sparse2Corpus(full_sparse_data, documents_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a dictionary for the LDA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.VocabTransform at 0x1a192be198>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_gensim = {}\n",
    "for key, val in BoW.vocabulary_.items():\n",
    "    vocabulary_gensim[val] = key\n",
    "    \n",
    "dict = Dictionary()\n",
    "dict.merge_with(vocabulary_gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 29s, sys: 17.7 s, total: 20min 47s\n",
      "Wall time: 11min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda = LdaModel(gensim_corpus_data, num_topics = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-269803afe120>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlda_data\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgensim_corpus_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lda' is not defined"
     ]
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "lda_data =  pyLDAvis.gensim.prepare(lda, gensim_corpus_data, dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.display(lda_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read train target and split data for validation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_log1p_recommends.csv'), \n",
    "                           index_col='id')\n",
    "y_train = train_target['log_recommends'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part_size = int(0.7 * train_target.shape[0])\n",
    "X_train_part_sparse = X_train_sparse[:train_part_size, :]\n",
    "y_train_part = y_train[:train_part_size]\n",
    "X_valid_sparse =  X_train_sparse[train_part_size:, :]\n",
    "y_valid = y_train[train_part_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train a simple Ridge model and check MAE on the validation set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the same Ridge with all available data, make predictions for the test set and form a submission file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission_file(prediction, filename,\n",
    "                          path_to_sample=os.path.join(PATH_TO_DATA, \n",
    "                                                      'sample_submission.csv')):\n",
    "    submission = pd.read_csv(path_to_sample, index_col='id')\n",
    "    \n",
    "    submission['log_recommends'] = prediction\n",
    "    submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(ridge_test_pred, os.path.join(PATH_TO_DATA,\n",
    "                                                    'assignment2_medium_submission.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now's the time for dirty Kaggle hacks. Form a submission file with all zeros. Make a submission. What do you get if you think about it? How is it going to help you with modifying your predictions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(np.zeros_like(ridge_test_pred), \n",
    "                      os.path.join(PATH_TO_DATA,\n",
    "                                   'medium_all_zeros_submission.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
